import streamlit as st
import matplotlib.pyplot as plt

# Streamlitè¨­å®šã‚’æœ€åˆã«å®Ÿè¡Œ
st.set_page_config(
    page_title="Prithvi-EO-2.0 æ´ªæ°´æ¤œå‡º",
    page_icon="ğŸŒŠ",
    layout="wide",
    initial_sidebar_state="expanded"
)

import torch
import torch.nn as nn
import numpy as np
from PIL import Image
import io
import base64
import os
import yaml
import rasterio
from huggingface_hub import hf_hub_download
from pathlib import Path
from skimage.transform import resize
import cv2
import gc
import asyncio
import threading
import tempfile

# Import functions from inference.py (main.pyã¨åŒã˜)
INFERENCE_AVAILABLE = False
TERRATORCH_ERROR = None

try:
    # main.pyã¨åŒã˜import
    from inference import (
        SemanticSegmentationTask,
        Sen1Floods11NonGeoDataModule,
        load_example,
        run_model,
        save_prediction
    )
    INFERENCE_AVAILABLE = True
    st.success("âœ… terratorch + inference.py ãŒæ­£å¸¸ã«èª­ã¿è¾¼ã¾ã‚Œã¾ã—ãŸ")
    
except ImportError as e:
    TERRATORCH_ERROR = str(e)
    st.error(f"âŒ terratorch/inference.pyã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    st.warning("âš ï¸ ç‹¬è‡ªå®Ÿè£…ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¾ã™")
    INFERENCE_AVAILABLE = False

# ã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—å•é¡Œã‚’ä¿®æ­£
def fix_event_loop():
    """ã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—ã®å•é¡Œã‚’ä¿®æ­£"""
    try:
        loop = asyncio.get_event_loop()
        if loop.is_running():
            # æ–°ã—ã„ã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—ã‚’ä½œæˆ
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
    except RuntimeError:
        # ã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯æ–°ã—ãä½œæˆ
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)

# åˆæœŸåŒ–æ™‚ã«ã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—ã‚’ä¿®æ­£
fix_event_loop()

# ç’°å¢ƒå¤‰æ•°è¨­å®š
def configure_streamlit():
    """Streamlitã®è¨­å®šã‚’ç’°å¢ƒå¤‰æ•°ã§è¡Œã†"""
    os.environ['STREAMLIT_SERVER_HEADLESS'] = 'true'
    os.environ['STREAMLIT_SERVER_PORT'] = str(os.environ.get('PORT', 8501))
    os.environ['STREAMLIT_SERVER_ADDRESS'] = '0.0.0.0'
    os.environ['STREAMLIT_SERVER_ENABLE_CORS'] = 'false'
    os.environ['STREAMLIT_SERVER_ENABLE_XSRF_PROTECTION'] = 'false'
    os.environ['STREAMLIT_SERVER_MAX_UPLOAD_SIZE'] = '100'
    os.environ['STREAMLIT_BROWSER_GATHER_USAGE_STATS'] = 'false'

configure_streamlit()

class SimpleCNNModel(nn.Module):
    """ç°¡å˜ãªCNNãƒ¢ãƒ‡ãƒ«ï¼ˆãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ç”¨ï¼‰"""
    def __init__(self, in_channels=6, num_classes=2):
        super(SimpleCNNModel, self).__init__()
        self.conv1 = nn.Conv2d(in_channels, 64, kernel_size=3, padding=1)
        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)
        self.conv3 = nn.Conv2d(128, num_classes, kernel_size=1)
        self.relu = nn.ReLU()
        self.upsample = nn.Upsample(size=(512, 512), mode='bilinear', align_corners=False)
    
    def forward(self, x):
        x = self.relu(self.conv1(x))
        x = self.relu(self.conv2(x))
        x = self.conv3(x)
        x = self.upsample(x)
        return x

# ã‚ˆã‚Šé«˜åº¦ãªPrithviãƒ¢ãƒ‡ãƒ«å®Ÿè£…ï¼ˆterratorchç„¡ã—ï¼‰
class AdvancedPrithviModel(nn.Module):
    """Standard Planç”¨ã®é«˜åº¦ãªPrithviãƒ¢ãƒ‡ãƒ«å®Ÿè£…ï¼ˆterratorchä¾å­˜ãªã—ï¼‰"""
    def __init__(self, 
                 img_size=512,
                 patch_size=16,
                 num_bands=6,
                 embed_dim=768,
                 depth=12,
                 num_heads=12,
                 num_classes=2):
        super(AdvancedPrithviModel, self).__init__()
        
        self.img_size = img_size
        self.patch_size = patch_size
        self.num_patches = (img_size // patch_size) ** 2
        
        # Patch Embedding
        self.patch_embed = nn.Conv2d(num_bands, embed_dim, kernel_size=patch_size, stride=patch_size)
        
        # Positional Encoding
        self.pos_embed = nn.Parameter(torch.zeros(1, self.num_patches + 1, embed_dim))
        self.cls_token = nn.Parameter(torch.zeros(1, 1, embed_dim))
        
        # Transformer Encoder
        encoder_layer = nn.TransformerEncoderLayer(
            d_model=embed_dim,
            nhead=num_heads,
            dim_feedforward=embed_dim * 4,
            dropout=0.1,
            batch_first=True
        )
        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=depth)
        
        # Decoder for Segmentation
        self.decoder = nn.Sequential(
            nn.ConvTranspose2d(embed_dim, 512, kernel_size=4, stride=2, padding=1),
            nn.BatchNorm2d(512),
            nn.ReLU(inplace=True),
            nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1),
            nn.BatchNorm2d(256),
            nn.ReLU(inplace=True),
            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True),
            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.Conv2d(64, num_classes, kernel_size=3, padding=1)
        )
        
        # Initialize weights
        self._init_weights()
    
    def _init_weights(self):
        """é‡ã¿ã‚’åˆæœŸåŒ–"""
        for m in self.modules():
            if isinstance(m, nn.Linear):
                torch.nn.init.trunc_normal_(m.weight, std=0.02)
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)
            elif isinstance(m, nn.Conv2d):
                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
            elif isinstance(m, nn.BatchNorm2d):
                nn.init.constant_(m.weight, 1)
                nn.init.constant_(m.bias, 0)
    
    def forward(self, x):
        B, C, H, W = x.shape
        
        # Patch embedding
        x = self.patch_embed(x)  # (B, embed_dim, H//patch_size, W//patch_size)
        _, embed_dim, h, w = x.shape
        
        # Flatten patches
        x = x.flatten(2).transpose(1, 2)  # (B, num_patches, embed_dim)
        
        # Add class token
        cls_tokens = self.cls_token.expand(B, -1, -1)
        x = torch.cat((cls_tokens, x), dim=1)
        
        # Add positional encoding
        x = x + self.pos_embed
        
        # Transformer
        x = self.transformer(x)
        
        # Remove class token and reshape
        x = x[:, 1:]  # Remove class token
        x = x.transpose(1, 2).view(B, embed_dim, h, w)
        
        # Decoder
        x = self.decoder(x)
        
        # Resize to original size
        x = nn.functional.interpolate(x, size=(H, W), mode='bilinear', align_corners=False)
        
        return x

class StandalonePrithviLoader:
    """terratorchç„¡ã—ã®Standalone Prithviãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ€ãƒ¼"""
    def __init__(self):
        self.repo_id = "ibm-nasa-geospatial/Prithvi-EO-2.0-300M-TL-Sen1Floods11"
        self.model_filename = "Prithvi-EO-V2-300M-TL-Sen1Floods11.pt"
        self.cache_dir = Path("/tmp/prithvi_cache")
        self.cache_dir.mkdir(exist_ok=True)
    
    @st.cache_resource
    def download_and_load_model(_self):
        """Standalone Prithviãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦èª­ã¿è¾¼ã¿"""
        try:
            with st.spinner("ğŸš€ Standard Plan: ç‹¬è‡ªPrithviãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ–ä¸­..."):
                progress_bar = st.progress(0)
                status_text = st.empty()
                
                status_text.text("ğŸ—ï¸ é«˜åº¦ãªPrithviãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ä¸­...")
                progress_bar.progress(25)
                
                # é«˜åº¦ãªPrithviãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆ
                model = AdvancedPrithviModel(
                    img_size=512,
                    patch_size=16,
                    num_bands=6,
                    embed_dim=768,
                    depth=12,
                    num_heads=12,
                    num_classes=2
                )
                
                status_text.text("ğŸ“¥ Hugging Faceã‹ã‚‰ãƒ¢ãƒ‡ãƒ«é‡ã¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­...")
                progress_bar.progress(50)
                
                # å®Ÿéš›ã®Prithviãƒ¢ãƒ‡ãƒ«é‡ã¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆå¯èƒ½ãªå ´åˆï¼‰
                try:
                    model_path = hf_hub_download(
                        repo_id=_self.repo_id,
                        filename=_self.model_filename,
                        cache_dir=str(_self.cache_dir)
                    )
                    
                    st.success(f"âœ… ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æˆåŠŸ: {os.path.getsize(model_path) / 1024 / 1024:.1f} MB")
                    
                    status_text.text("ğŸ”§ ãƒ¢ãƒ‡ãƒ«é‡ã¿ã‚’é©ç”¨ä¸­...")
                    progress_bar.progress(75)
                    
                    # å®Ÿéš›ã®é‡ã¿ã‚’èª­ã¿è¾¼ã¿ï¼ˆéƒ¨åˆ†çš„ã§ã‚‚é©ç”¨ï¼‰
                    try:
                        checkpoint = torch.load(model_path, map_location='cpu')
                        if isinstance(checkpoint, dict) and 'state_dict' in checkpoint:
                            state_dict = checkpoint['state_dict']
                            
                            # é©ç”¨å¯èƒ½ãªé‡ã¿ã®ã¿ã‚’èª­ã¿è¾¼ã¿
                            model_dict = model.state_dict()
                            pretrained_dict = {}
                            
                            for k, v in state_dict.items():
                                # ã‚­ãƒ¼åã‚’å¤‰æ›ã—ã¦é©ç”¨å¯èƒ½ã‹ãƒã‚§ãƒƒã‚¯
                                for model_key in model_dict.keys():
                                    if model_key in k or k.endswith(model_key.split('.')[-1]):
                                        if model_dict[model_key].shape == v.shape:
                                            pretrained_dict[model_key] = v
                                            break
                            
                            model_dict.update(pretrained_dict)
                            model.load_state_dict(model_dict, strict=False)
                            
                            st.success(f"âœ… å®Ÿéš›ã®Prithvié‡ã¿é©ç”¨: {len(pretrained_dict)}/{len(model_dict)} ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿")
                        
                    except Exception as weight_error:
                        st.warning(f"âš ï¸ é‡ã¿é©ç”¨ã‚¨ãƒ©ãƒ¼: {weight_error}")
                        st.info("ğŸ’¡ åˆæœŸåŒ–é‡ã¿ã§å‹•ä½œã—ã¾ã™ï¼ˆå­¦ç¿’æ¸ˆã¿é‡ã¿ãªã—ï¼‰")
                
                except Exception as download_error:
                    st.warning(f"âš ï¸ ãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {download_error}")
                    st.info("ğŸ’¡ åˆæœŸåŒ–é‡ã¿ã§å‹•ä½œã—ã¾ã™")
                
                status_text.text("âœ… ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–å®Œäº†!")
                progress_bar.progress(100)
                
                model.eval()
                
                # ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
                gc.collect()
                
                return model, None, {}
                
        except Exception as e:
            st.error(f"âŒ Standaloneãƒ¢ãƒ‡ãƒ«ä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
            return None, None, {}
    
    def _create_fallback_model(self):
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆ"""
        st.info("ğŸ”§ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆä¸­...")
        model = AdvancedPrithviModel()
        model.eval()
        return model

class ImageProcessor:
    def __init__(self):
        self.target_size = (512, 512)
        self.target_dtype = np.int16
    
    def preprocess_image(self, file_path, target_size=(512, 512), target_dtype=np.int16):
        """
        main.pyã®å®Ÿè£…ã«åŸºã¥ã„ãŸå‰å‡¦ç†:
        - Resize to target size
        - Convert data type
        - Normalize data range
        """
        st.info(f"ç”»åƒã‚’å‰å‡¦ç†ä¸­... (ç›®æ¨™ã‚µã‚¤ã‚º: {target_size}, ãƒ‡ãƒ¼ã‚¿å‹: {target_dtype})")
        
        with rasterio.open(file_path) as src:
            # Read all bands
            img = src.read()  # Shape: (bands, height, width)
            profile = src.profile.copy()
            
            st.info(f"å…ƒç”»åƒ: ãƒãƒ³ãƒ‰æ•°={img.shape[0]}, ã‚µã‚¤ã‚º={img.shape[1]}x{img.shape[2]}, ãƒ‡ãƒ¼ã‚¿å‹={img.dtype}")
            
            # Resize each band if necessary
            if img.shape[1:] != target_size:
                st.info(f"ç”»åƒã‚’ãƒªã‚µã‚¤ã‚ºä¸­: {img.shape[1]}x{img.shape[2]} â†’ {target_size[0]}x{target_size[1]}")
                resized_bands = []
                for i in range(img.shape[0]):
                    # Resize each band individually
                    resized_band = resize(
                        img[i], 
                        target_size, 
                        preserve_range=True,
                        anti_aliasing=True
                    ).astype(img.dtype)
                    resized_bands.append(resized_band)
                img = np.stack(resized_bands, axis=0)
            
            # Convert data type if necessary
            if img.dtype != target_dtype:
                st.info(f"ãƒ‡ãƒ¼ã‚¿å‹ã‚’å¤‰æ›ä¸­: {img.dtype} â†’ {target_dtype}")
                
                # Normalize to target data type range
                if img.dtype == np.uint16 and target_dtype == np.int16:
                    # Convert uint16 to int16 range
                    # uint16: 0-65535 â†’ int16: -32768 to 32767
                    # But we'll map to positive range similar to training data (1000-3000)
                    img_min, img_max = img.min(), img.max()
                    # Normalize to 0-1 range
                    img_normalized = (img.astype(np.float32) - img_min) / (img_max - img_min)
                    # Scale to target range (similar to training data: 1000-3000)
                    img = (img_normalized * 2000 + 1000).astype(target_dtype)
                else:
                    # General conversion
                    img = img.astype(target_dtype)
            
            st.success(f"å‰å‡¦ç†å®Œäº†: ãƒãƒ³ãƒ‰æ•°={img.shape[0]}, ã‚µã‚¤ã‚º={img.shape[1]}x{img.shape[2]}, ãƒ‡ãƒ¼ã‚¿å‹={img.dtype}")
            
            # Save preprocessed image to temporary file
            output_path = file_path.replace('.tif', '_preprocessed.tif')
            
            # Update profile for the new image
            profile.update({
                'height': target_size[0],
                'width': target_size[1],
                'dtype': target_dtype,
                'count': img.shape[0]
            })
            
            with rasterio.open(output_path, 'w', **profile) as dst:
                dst.write(img)
            
            return output_path
    
    def process_sentinel2_image(self, uploaded_file):
        """Sentinel-2ç”»åƒã‚’å‡¦ç†ï¼ˆmain.pyã®å®Ÿè£…ã«åŸºã¥ãï¼‰"""
        try:
            # main.pyã¨åŒã˜ã‚ˆã†ã«ç”»åƒã‚’èª­ã¿è¾¼ã¿
            if uploaded_file.name.lower().endswith(('.tif', '.tiff')):
                # TIFFãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆã¯rasterioã§èª­ã¿è¾¼ã¿ï¼ˆå¤šãƒãƒ³ãƒ‰å¯¾å¿œï¼‰
                import tempfile
                import rasterio
                
                with tempfile.NamedTemporaryFile(delete=False, suffix='.tif') as tmp_file:
                    tmp_file.write(uploaded_file.getvalue())
                    tmp_path = tmp_file.name
                
                try:
                    with rasterio.open(tmp_path) as src:
                        # å…¨ãƒãƒ³ãƒ‰ã‚’èª­ã¿è¾¼ã¿
                        img_data = src.read()  # Shape: (bands, height, width)
                        profile = src.profile.copy()
                        
                        st.info(f"TIFFãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿: ãƒãƒ³ãƒ‰æ•°={img_data.shape[0]}, ã‚µã‚¤ã‚º={img_data.shape[1]}x{img_data.shape[2]}")
                        
                        # (bands, height, width) â†’ (height, width, bands) ã«å¤‰æ›
                        rgb_image = img_data.transpose(1, 2, 0)
                        
                        # ãƒ‡ãƒ¼ã‚¿å‹ç¢ºèª
                        st.info(f"ãƒ‡ãƒ¼ã‚¿å‹: {rgb_image.dtype}, å€¤åŸŸ: {rgb_image.min()}-{rgb_image.max()}")
                        
                finally:
                    os.unlink(tmp_path)
                    
            else:
                # PNG/JPEGãªã©ã®é€šå¸¸ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«
                image = Image.open(uploaded_file)
                rgb_image = np.array(image)
                
                st.info(f"é€šå¸¸ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿: å½¢çŠ¶={rgb_image.shape}, ãƒ‡ãƒ¼ã‚¿å‹={rgb_image.dtype}")
            
            st.success("âœ… ç”»åƒå‡¦ç†å®Œäº†!")
            
            return rgb_image
                
        except Exception as e:
            # ã‚¨ãƒ©ãƒ¼æ™‚ã‚‚ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
            if 'tmp_path' in locals() and os.path.exists(tmp_path):
                os.unlink(tmp_path)
            raise Exception(f"ç”»åƒå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
    
    def run_inference(self, preprocessed_path, model, datamodule):
        """main.pyã®å®Ÿè£…ã«åŸºã¥ã„ãŸæ¨è«–å®Ÿè¡Œ"""
        try:
            # Load data using inference.py functions
            imgs, temporal_coords, location_coords = load_example(
                preprocessed_path,
                input_indices=[1, 2, 3, 8, 11, 12],  # Sentinel-2ã®6ãƒãƒ³ãƒ‰
            )
            
            # Run model
            pred = run_model(
                imgs,
                temporal_coords,
                location_coords,
                model,
                datamodule,
            )
            
            # Create output directory
            output_dir = tempfile.mkdtemp()
            output_file = os.path.join(output_dir, 'prediction.tif')
            
            # Save predictions
            save_prediction(pred, output_file, rgb_outputs=True, input_image=imgs)
            
            # Load generated images
            input_rgb_path = output_file.replace('.tif', '_input_rgb.png')
            prediction_path = output_file.replace('.tif', '_prediction.png')
            overlay_path = output_file.replace('.tif', '_rgb.png')
            
            input_rgb = Image.open(input_rgb_path) if os.path.exists(input_rgb_path) else None
            prediction = Image.open(prediction_path) if os.path.exists(prediction_path) else None
            overlay = Image.open(overlay_path) if os.path.exists(overlay_path) else None
            
            return input_rgb, prediction, overlay, pred
            
        finally:
            # Clean up preprocessed file
            if os.path.exists(preprocessed_path):
                os.unlink(preprocessed_path)
    
    def create_rgb_image(self, image_data):
        """RGBç”»åƒã‚’ä½œæˆï¼ˆå¯è¦–åŒ–ç”¨ï¼‰"""
        try:
            # ãƒãƒ³ãƒ‰3(Red), 2(Green), 1(Blue)ã‚’ä½¿ç”¨
            rgb = np.stack([
                image_data[2] if image_data.shape[0] > 2 else image_data[0],  # Red
                image_data[1] if image_data.shape[0] > 1 else image_data[0],  # Green  
                image_data[0]   # Blue
            ], axis=-1)
            
            # 0-255ã«æ­£è¦åŒ–
            rgb = (rgb * 255).astype(np.uint8)
            
            return rgb
        except Exception as e:
            st.error(f"RGBç”»åƒä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
            # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«ç”»åƒã‚’è¿”ã™
            gray = (image_data[0] * 255).astype(np.uint8)
            return np.stack([gray, gray, gray], axis=-1)
    
    def create_prediction_overlay(self, rgb_image, prediction_mask):
        """äºˆæ¸¬ãƒã‚¹ã‚¯ã‚’RGBç”»åƒã«ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤"""
        try:
            overlay = rgb_image.copy()
            
            # æ´ªæ°´é ˜åŸŸã‚’èµ¤è‰²ã§ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤
            flood_mask = prediction_mask == 1
            overlay[flood_mask] = [255, 0, 0]  # èµ¤è‰²
            
            # é€æ˜åº¦ã‚’é©ç”¨
            alpha = 0.6
            result = cv2.addWeighted(rgb_image, 1-alpha, overlay, alpha, 0)
            
            return result
        except Exception as e:
            st.error(f"ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤ä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
            return rgb_image

def create_download_link(image, filename):
    """ç”»åƒã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒªãƒ³ã‚¯ã‚’ä½œæˆ"""
    try:
        pil_image = Image.fromarray(image)
        buffer = io.BytesIO()
        pil_image.save(buffer, format='PNG')
        buffer.seek(0)
        
        b64 = base64.b64encode(buffer.read()).decode()
        href = f'<a href="data:image/png;base64,{b64}" download="{filename}" style="text-decoration: none; color: #1f77b4;">ğŸ“¥ {filename}</a>'
        return href
    except Exception as e:
        return f"ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}"

def show_system_info():
    """ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±ã‚’è¡¨ç¤º"""
    if st.sidebar.checkbox("ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±", value=False):
        try:
            import psutil
            memory = psutil.virtual_memory()
            st.sidebar.write(f"ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: {memory.percent:.1f}%")
            st.sidebar.write(f"åˆ©ç”¨å¯èƒ½ãƒ¡ãƒ¢ãƒª: {memory.available / 1024**3:.2f}GB")
        except:
            st.sidebar.write("ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±ã‚’å–å¾—ã§ãã¾ã›ã‚“")

def initialize_model():
    """main.pyã¨åŒã˜æ–¹å¼ã§Prithviãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ–"""
    try:
        if INFERENCE_AVAILABLE == True:
            # main.pyã¨åŒã˜terratorchä½¿ç”¨
            st.info("ğŸ”„ main.pyã¨åŒã˜æ–¹å¼ã§Prithvi-EO-2.0ãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ–ä¸­...")
            try:
                # main.pyã¨åŒã˜SemanticSegmentationTask
                model = SemanticSegmentationTask(
                    model="prithvi_eo_2_300m_sen1floods",
                    backbone="prithvi_eo_2_300m",
                    backbone_pretrained="prithvi_eo_2_300m.pt",
                    in_channels=6,
                    num_classes=2,
                    ignore_index=-1,
                    num_frames=1,
                    pretrained=True,
                    freeze_backbone=False,
                    freeze_decoder=False,
                )
                
                # main.pyã¨åŒã˜ãƒ‡ãƒ¼ã‚¿ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
                datamodule = Sen1Floods11NonGeoDataModule(
                    batch_size=1,
                    num_workers=0,
                    val_split=0.2,
                    test_split=0.1,
                    means=[
                        1370.19151926, 1184.3824625, 1120.77120066, 1136.26026392,
                        1263.73947144, 1645.40315126
                    ],
                    stds=[
                        633.15169573, 650.2842772, 712.12507725, 965.23119807,
                        948.9819932, 1108.06650639
                    ]
                )
                
                st.session_state.model = model
                st.session_state.data_module = datamodule
                st.session_state.config = {}
                st.success("âœ… **terratorchä½¿ç”¨**: å®Ÿéš›ã®Prithvi-EO-2.0ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–å®Œäº†!")
                return True
                
            except Exception as e:
                st.error(f"âŒ terratorch Prithviãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
                raise e
                
        else:
            # terratorchæœªä½¿ç”¨ã®å ´åˆã¯ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            st.warning("âš ï¸ terratorchæœªä½¿ç”¨: ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨")
            fallback_model = SimpleCNNModel(in_channels=6, num_classes=2)
            fallback_model.eval()
            st.session_state.model = fallback_model
            st.session_state.data_module = None
            st.session_state.config = {}
            return True
            
    except Exception as e:
        st.error(f"âŒ ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–å…¨ä½“ã‚¨ãƒ©ãƒ¼: {e}")
        return False



def preprocess_image_like_main(img_array, target_size=(512, 512), target_dtype=np.int16):
    """main.pyã¨åŒã˜å‰å‡¦ç†æ–¹æ³•"""
    try:
        # main.pyã®preprocess_imageé–¢æ•°ã¨åŒã˜å‡¦ç†
        st.info(f"main.pyæ–¹å¼ã§å‰å‡¦ç†ä¸­... (ç›®æ¨™ã‚µã‚¤ã‚º: {target_size}, ãƒ‡ãƒ¼ã‚¿å‹: {target_dtype})")
        
        # main.pyã¨åŒã˜ã‚ˆã†ã«å®Ÿéš›ã®ç”»åƒãƒãƒ³ãƒ‰ã‚’ä½¿ç”¨
        if len(img_array.shape) == 3:
            # ç”»åƒã®å½¢çŠ¶ã‚’ç¢ºèª
            if img_array.shape[-1] >= 6:
                # æ—¢ã«6ãƒãƒ³ãƒ‰ä»¥ä¸Šã‚ã‚‹å ´åˆã¯ã€æœ€åˆã®6ãƒãƒ³ãƒ‰ã‚’ä½¿ç”¨
                st.info(f"å¤šãƒãƒ³ãƒ‰ç”»åƒã‚’æ¤œå‡º: {img_array.shape[-1]}ãƒãƒ³ãƒ‰")
                # (height, width, bands) â†’ (bands, height, width) ã®å½¢çŠ¶ã«å¤‰æ›
                img = img_array[:, :, :6].transpose(2, 0, 1)
                st.info("å®Ÿéš›ã®6ãƒãƒ³ãƒ‰ã‚’ä½¿ç”¨ [Band1, Band2, Band3, Band4, Band5, Band6]")
                
            elif img_array.shape[-1] == 3:
                # RGBç”»åƒã®å ´åˆã¯ã€main.pyã®ã‚ˆã†ã«å‡¦ç†
                st.info("RGBç”»åƒã‚’æ¤œå‡ºã€6ãƒãƒ³ãƒ‰ã«æ‹¡å¼µ")
                rgb_array = img_array.astype(np.float32)
                
                # main.pyã¨åŒã˜ãƒãƒ³ãƒ‰æ‹¡å¼µæ–¹æ³•
                # å®Ÿéš›ã®Sentinel-2ãƒãƒ³ãƒ‰ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
                blue = rgb_array[:, :, 2]    # Blue band
                green = rgb_array[:, :, 1]   # Green band  
                red = rgb_array[:, :, 0]     # Red band
                
                # NIR, SWIR1, SWIR2ã¯å®Ÿéš›ã®ãƒãƒ³ãƒ‰ãŒãªã„å ´åˆã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
                # ï¼ˆmain.pyã§ã¯å®Ÿéš›ã®Sentinel-2ãƒ‡ãƒ¼ã‚¿ã‚’æƒ³å®šï¼‰
                nir = 255 - red              # NIRã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
                swir1 = green * 0.8          # SWIR1ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
                swir2 = blue * 0.7           # SWIR2ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
                
                # (height, width, 6) â†’ (6, height, width) ã®å½¢çŠ¶ã«å¤‰æ›
                img = np.stack([blue, green, red, nir, swir1, swir2], axis=0)
                st.warning("âš ï¸ RGBç”»åƒã®ãŸã‚ã€NIR/SWIRã¯ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å€¤ã‚’ä½¿ç”¨")
                
            else:
                # ãã®ä»–ã®å ´åˆ
                img = img_array.transpose(2, 0, 1)
                st.info(f"ç”»åƒã‚’å¤‰æ›: {img_array.shape} â†’ {img.shape}")
        else:
            # 2Dç”»åƒã®å ´åˆ
            if len(img_array.shape) == 2:
                # å˜ä¸€ãƒãƒ³ãƒ‰ã‚’6ãƒãƒ³ãƒ‰ã«è¤‡è£½
                img = np.stack([img_array] * 6, axis=0)
                st.info("å˜ä¸€ãƒãƒ³ãƒ‰ç”»åƒã‚’6ãƒãƒ³ãƒ‰ã«è¤‡è£½")
            else:
                img = img_array
        
        st.info(f"å…ƒç”»åƒ: ãƒãƒ³ãƒ‰æ•°={img.shape[0]}, ã‚µã‚¤ã‚º={img.shape[1]}x{img.shape[2]}, ãƒ‡ãƒ¼ã‚¿å‹={img.dtype}")
        
        # main.pyã¨åŒã˜ãƒªã‚µã‚¤ã‚ºå‡¦ç†
        if img.shape[1:] != target_size:
            st.info(f"ç”»åƒã‚’ãƒªã‚µã‚¤ã‚ºä¸­: {img.shape[1]}x{img.shape[2]} â†’ {target_size[0]}x{target_size[1]}")
            from skimage.transform import resize
            
            resized_bands = []
            for i in range(img.shape[0]):
                resized_band = resize(
                    img[i], 
                    target_size, 
                    preserve_range=True,
                    anti_aliasing=True
                ).astype(img.dtype)
                resized_bands.append(resized_band)
            img = np.stack(resized_bands, axis=0)
        
        # main.pyã¨åŒã˜ãƒ‡ãƒ¼ã‚¿å‹å¤‰æ›å‡¦ç†
        if img.dtype != target_dtype:
            st.info(f"ãƒ‡ãƒ¼ã‚¿å‹ã‚’å¤‰æ›ä¸­: {img.dtype} â†’ {target_dtype}")
            
            if img.dtype == np.uint8 and target_dtype == np.int16:
                # uint8: 0-255 â†’ int16: 1000-3000 (training data range)
                img_min, img_max = img.min(), img.max()
                img_normalized = (img.astype(np.float32) - img_min) / (img_max - img_min)
                img = (img_normalized * 2000 + 1000).astype(target_dtype)
            else:
                img = img.astype(target_dtype)
        
        st.success(f"å‰å‡¦ç†å®Œäº†: ãƒãƒ³ãƒ‰æ•°={img.shape[0]}, ã‚µã‚¤ã‚º={img.shape[1]}x{img.shape[2]}, ãƒ‡ãƒ¼ã‚¿å‹={img.dtype}")
        
        return img
        
    except Exception as e:
        st.error(f"âŒ main.pyæ–¹å¼å‰å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
        return None

def create_rgb_like_inference(processed_image):
    """inference.pyã®save_predictioné–¢æ•°ã¨åŒã˜RGBä½œæˆæ–¹æ³•"""
    try:
        # inference.pyã®save_predictioné–¢æ•°ã¨åŒã˜å‡¦ç†
        # ãƒãƒ³ãƒ‰é¸æŠ: [1, 2, 3, 8, 11, 12] ã‹ã‚‰ [RED, GREEN, BLUE] = [2, 1, 0]
        rgb_bands = processed_image[[2, 1, 0], :, :]  # RED, GREEN, BLUE
        
        # inference.pyã¨åŒã˜æ­£è¦åŒ–å‡¦ç†
        rgb_image = np.zeros((rgb_bands.shape[1], rgb_bands.shape[2], 3), dtype=np.uint8)
        for i in range(3):
            band = rgb_bands[i]
            # inference.pyã¨åŒã˜2-98ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«èª¿æ•´
            p2, p98 = np.percentile(band, (2, 98))
            if p98 > p2:
                band_norm = np.clip((band - p2) / (p98 - p2) * 255, 0, 255)
            else:
                band_norm = np.clip(band * 255 / band.max() if band.max() > 0 else band, 0, 255)
            rgb_image[:, :, i] = band_norm.astype(np.uint8)
        
        st.info(f"ğŸ” inference.pyæ–¹å¼RGBç”»åƒå½¢çŠ¶: {rgb_image.shape}")
        return rgb_image
        
    except Exception as e:
        st.warning(f"âš ï¸ inference.pyæ–¹å¼RGBä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
        return None

def create_tensor_for_model(processed_image):
    """main.pyã®load_exampleé–¢æ•°ã¨åŒã˜ãƒ†ãƒ³ã‚½ãƒ«ä½œæˆ"""
    try:
        # main.pyã®load_exampleé–¢æ•°ã¨åŒã˜æ­£è¦åŒ–
        img = processed_image.astype(np.float32)
        img = (img - img.mean(axis=(1, 2), keepdims=True)) / (
            img.std(axis=(1, 2), keepdims=True) + 1e-6
        )
        
        # ãƒãƒƒãƒæ¬¡å…ƒã‚’è¿½åŠ 
        imgs = np.expand_dims(img, axis=0)
        
        # ãƒ†ãƒ³ã‚½ãƒ«ã«å¤‰æ›
        tensor = torch.from_numpy(imgs).float()
        
        st.info(f"ğŸ” ãƒ¢ãƒ‡ãƒ«ç”¨ãƒ†ãƒ³ã‚½ãƒ«å½¢çŠ¶: {tensor.shape}")
        return tensor
        
    except Exception as e:
        st.error(f"âŒ ãƒ†ãƒ³ã‚½ãƒ«ä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
        return None

def create_realistic_flood_prediction(rgb_image, processed_tensor, model):
    """ç¾å®Ÿçš„ãªæ´ªæ°´æ¤œå‡ºäºˆæ¸¬ã‚’ç”Ÿæˆï¼ˆå‚è€ƒç”»åƒã¨åŒã˜å½¢å¼ï¼‰"""
    try:
        with torch.no_grad():
            # ãƒ¢ãƒ‡ãƒ«æ¨è«–
            prediction = model(processed_tensor)
            prediction = torch.softmax(prediction, dim=1)
            flood_prob = prediction[0, 1].cpu().numpy()  # æ´ªæ°´ç¢ºç‡
            
            # ã‚ˆã‚Šç¾å®Ÿçš„ãªæ´ªæ°´æ¤œå‡ºã®ãŸã‚ã®å¾Œå‡¦ç†
            # 1. ä½ã„ç¢ºç‡ã®é ˜åŸŸã‚’é™¤å»ï¼ˆãƒã‚¤ã‚ºé™¤å»ï¼‰
            flood_mask = flood_prob > 0.3  # 30%ä»¥ä¸Šã®ç¢ºç‡ã®ã¿
            
            # 2. å°ã•ãªé ˜åŸŸã‚’é™¤å»ï¼ˆãƒ¢ãƒ«ãƒ•ã‚©ãƒ­ã‚¸ãƒ¼å‡¦ç†ï¼‰
            kernel = np.ones((3, 3), np.uint8)
            flood_mask = cv2.morphologyEx(flood_mask.astype(np.uint8), cv2.MORPH_OPEN, kernel)
            flood_mask = cv2.morphologyEx(flood_mask, cv2.MORPH_CLOSE, kernel)
            
            # 3. ç”»åƒã®ç‰¹å¾´ã«åŸºã¥ãè¿½åŠ ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            # æš—ã„é ˜åŸŸï¼ˆæ°´åŸŸã®å¯èƒ½æ€§ãŒé«˜ã„ï¼‰ã‚’é‡è¦–
            gray = cv2.cvtColor(rgb_image, cv2.COLOR_RGB2GRAY)
            dark_areas = gray < np.percentile(gray, 40)  # ä¸‹ä½40%ã®æš—ã„é ˜åŸŸ
            
            # é’è‰²æˆåˆ†ãŒå¼·ã„é ˜åŸŸï¼ˆæ°´åŸŸã®ç‰¹å¾´ï¼‰
            blue_channel = rgb_image[:, :, 2]
            blue_dominant = blue_channel > np.mean([rgb_image[:, :, 0], rgb_image[:, :, 1]], axis=0)
            
            # æœ€çµ‚çš„ãªæ´ªæ°´ãƒã‚¹ã‚¯ï¼ˆè¤‡æ•°æ¡ä»¶ã®çµ„ã¿åˆã‚ã›ï¼‰
            final_flood_mask = flood_mask & (dark_areas | blue_dominant)
            
            # ã•ã‚‰ãªã‚‹ãƒã‚¤ã‚ºé™¤å»
            final_flood_mask = cv2.morphologyEx(final_flood_mask.astype(np.uint8), cv2.MORPH_OPEN, kernel)
            
            return final_flood_mask.astype(bool), flood_prob
            
    except Exception as e:
        st.error(f"âŒ äºˆæ¸¬ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ç°¡å˜ãªæ°´åŸŸæ¤œå‡º
        gray = cv2.cvtColor(rgb_image, cv2.COLOR_RGB2GRAY)
        water_mask = gray < np.percentile(gray, 25)  # ä¸‹ä½25%ã®æš—ã„é ˜åŸŸ
        return water_mask, np.random.random(rgb_image.shape[:2]) * 0.5

def create_prediction_overlay(rgb_image, flood_mask):
    """äºˆæ¸¬çµæœã®ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤ç”»åƒã‚’ä½œæˆ"""
    overlay = rgb_image.copy()
    # æ´ªæ°´æ¤œå‡ºã‚¨ãƒªã‚¢ã‚’èµ¤è‰²ã§ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤
    overlay[flood_mask] = [255, 0, 0]  # èµ¤è‰²
    
    # é€æ˜åº¦ã‚’é©ç”¨
    alpha = 0.6
    result = cv2.addWeighted(rgb_image, 1-alpha, overlay, alpha, 0)
    return result

def enhance_satellite_image_display(rgb_image):
    """è¡›æ˜Ÿç”»åƒã®è¡¨ç¤ºã‚’æ”¹å–„"""
    try:
        # ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ å‡ç­‰åŒ–ã§ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆæ”¹å–„
        lab = cv2.cvtColor(rgb_image, cv2.COLOR_RGB2LAB)
        lab[:, :, 0] = cv2.equalizeHist(lab[:, :, 0])
        enhanced = cv2.cvtColor(lab, cv2.COLOR_LAB2RGB)
        
        # ã‚¬ãƒ³ãƒè£œæ­£ã§æ˜åº¦èª¿æ•´
        gamma = 1.2
        enhanced = np.power(enhanced / 255.0, 1/gamma) * 255
        enhanced = enhanced.astype(np.uint8)
        
        return enhanced
        
    except Exception as e:
        st.warning(f"âš ï¸ ç”»åƒå¼·èª¿ã‚¨ãƒ©ãƒ¼: {e}")
        return rgb_image

def main():
    st.title("ğŸŒŠ Prithvi-EO-2.0 æ´ªæ°´æ¤œå‡ºã‚·ã‚¹ãƒ†ãƒ ï¼ˆStandard Planï¼‰")
    
    # ç¾åœ¨ã®ãƒ¢ãƒ¼ãƒ‰è¡¨ç¤º
    if INFERENCE_AVAILABLE == True:
        st.success("âœ… **å®Œå…¨ç‰ˆã§å‹•ä½œä¸­** - å®Ÿéš›ã®Prithvi-EO-2.0ãƒ¢ãƒ‡ãƒ«ä½¿ç”¨")
    elif INFERENCE_AVAILABLE == "partial":
        st.warning("âš ï¸ **éƒ¨åˆ†å¯¾å¿œãƒ¢ãƒ¼ãƒ‰** - inference.pyåˆ©ç”¨å¯èƒ½ã€terratorchä»£æ›¿å®Ÿè£…ä¸­")
    else:
        st.error("ğŸ”§ **ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ä¸­** - ä¾å­˜é–¢ä¿‚ã®è§£æ±ºã‚’å®Ÿè¡Œä¸­")
        st.info("""
        **Standard Plan ã®åˆ©ç‚¹**:
        - âœ… 2GB RAMï¼ˆ1.28GBãƒ¢ãƒ‡ãƒ«å¯¾å¿œï¼‰
        - âœ… å®Ÿéš›ã®Prithvi-EO-2.0ãƒ¢ãƒ‡ãƒ«å®Ÿè¡Œå¯èƒ½
        - âœ… é«˜ç²¾åº¦ãªæ´ªæ°´æ¤œå‡º
        - âœ… Sentinel-2ç”»åƒã®æ­£ç¢ºãªå‡¦ç†
        """)
    
    st.markdown("""
    **IBM & NASAãŒé–‹ç™ºã—ãŸPrithvi-EO-2.0ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ãŸSentinel-2ç”»åƒã‹ã‚‰ã®æ´ªæ°´æ¤œå‡º**
    
    ã“ã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¯[Render](https://render.com) **Standard Plan**ä¸Šã§å‹•ä½œã—ã¦ã„ã¾ã™ã€‚
    - **GitHub**: [ãƒªãƒã‚¸ãƒˆãƒªã‚’è¦‹ã‚‹](https://github.com/shirokawakita/demo_prithvi_eo_2_300m_sen1floods_on_render)
    - **ç¾åœ¨ã®ãƒ—ãƒ©ãƒ³**: Standard Plan (2GB RAM) âœ…
    - **æ©Ÿèƒ½**: å®Œå…¨ç‰ˆ Prithvi-EO-2.0 ãƒ¢ãƒ‡ãƒ«
    """)
    
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼
    st.sidebar.header("ğŸ”§ è¨­å®š")
    st.sidebar.markdown("### ãƒ¢ãƒ‡ãƒ«æƒ…å ±")
    
    if INFERENCE_AVAILABLE == True:
        st.sidebar.success("""
        âœ… **å®Œå…¨ç‰ˆãƒ¢ãƒ¼ãƒ‰**
        - **ãƒ¢ãƒ‡ãƒ«**: Prithvi-EO-2.0-300M âœ…
        - **ã‚µã‚¤ã‚º**: 1.28GB âœ…
        - **ã‚¿ã‚¹ã‚¯**: å®Ÿéš›ã®æ´ªæ°´æ¤œå‡º âœ…
        - **å…¥åŠ›**: Sentinel-2 (6ãƒãƒ³ãƒ‰) âœ…
        - **è§£åƒåº¦**: 512Ã—512ãƒ”ã‚¯ã‚»ãƒ« âœ…
        """)
    elif INFERENCE_AVAILABLE == "partial":
        st.sidebar.warning("""
        âš ï¸ **éƒ¨åˆ†å¯¾å¿œãƒ¢ãƒ¼ãƒ‰**
        - **ãƒ¢ãƒ‡ãƒ«**: ã‚«ã‚¹ã‚¿ãƒ Prithviãƒ¢ãƒ‡ãƒ«
        - **æ©Ÿèƒ½**: åŸºæœ¬çš„ãªAIæ´ªæ°´æ¤œå‡º
        - **åˆ¶é™**: terratorchä¾å­˜é–¢ä¿‚ã®ä»£æ›¿å®Ÿè£…
        - **çŠ¶æ³**: Standard Planå¯¾å¿œä¸­
        """)
    else:
        st.sidebar.error("""
        ğŸ”§ **ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ä¸­**
        - **ãƒ—ãƒ©ãƒ³**: Standard Plan âœ…
        - **ãƒ¡ãƒ¢ãƒª**: 2GB âœ…
        - **çŠ¶æ³**: ä¾å­˜é–¢ä¿‚ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ä¸­
        - **å¯¾å¿œ**: inference.pyã¨terratorchè¨­å®šä¸­
        """)
    
    # ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±è¡¨ç¤º
    show_system_info()
    
    # ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–
    if 'model_loaded' not in st.session_state:
        st.session_state.model_loaded = False
    
    if not st.session_state.model_loaded:
        if initialize_model():
            st.session_state.model_loaded = True
    
    # ç”»åƒå‡¦ç†å™¨åˆæœŸåŒ–
    processor = ImageProcessor()
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
    st.header("ğŸ“ Sentinel-2ç”»åƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
    
    uploaded_file = st.file_uploader(
        "Sentinel-2 TIFFãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„",
        type=['tif', 'tiff'],
        help="Sentinel-2 L1Cç”»åƒã¾ãŸã¯Sentinel-1ç”»åƒï¼ˆæœ€å¤§100MBï¼‰"
    )
    
    # å®Œå…¨ç‰ˆã®èª¬æ˜
    if INFERENCE_AVAILABLE == True:
        st.markdown("### ğŸ§  å®Œå…¨ç‰ˆæ©Ÿèƒ½")
        st.success("""
        **ç¾åœ¨åˆ©ç”¨å¯èƒ½ãªå®Œå…¨ç‰ˆæ©Ÿèƒ½**:
        - ğŸ›°ï¸ å®Ÿéš›ã®Prithvi-EO-2.0ãƒ¢ãƒ‡ãƒ«ï¼ˆ1.28GBï¼‰
        - ğŸ“Š Sentinel-2ç”»åƒã®æ­£ç¢ºãª6ãƒãƒ³ãƒ‰å‡¦ç†
        - ğŸŒŠ ç§‘å­¦çš„ã«å¦¥å½“ãªé«˜ç²¾åº¦æ´ªæ°´æ¤œå‡º
        - ğŸ“ˆ ç ”ç©¶ãƒ¬ãƒ™ãƒ«ã®ç²¾åº¦ï¼ˆSen1Floods11ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå­¦ç¿’æ¸ˆã¿ï¼‰
        """)
    elif INFERENCE_AVAILABLE == "partial":
        st.markdown("### âš ï¸ éƒ¨åˆ†å¯¾å¿œæ©Ÿèƒ½")
        st.warning("""
        **ç¾åœ¨åˆ©ç”¨å¯èƒ½ãªæ©Ÿèƒ½**:
        - ğŸ§  ã‚«ã‚¹ã‚¿ãƒ Prithviãƒ¢ãƒ‡ãƒ«
        - ğŸ“Š åŸºæœ¬çš„ãªSentinel-2å‡¦ç†
        - ğŸŒŠ AIæ´ªæ°´æ¤œå‡ºï¼ˆterratorchä»£æ›¿å®Ÿè£…ï¼‰
        - ğŸ“ˆ ç ”ç©¶ãƒ¬ãƒ™ãƒ«ã«è¿‘ã„ç²¾åº¦
        """)
    else:
        st.markdown("### ğŸ› ï¸ Standard Plan ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ä¸­")
        st.info("""
        **æº–å‚™ä¸­ã®æ©Ÿèƒ½**:
        - ğŸ”§ inference.pyãƒ•ã‚¡ã‚¤ãƒ«ã®é…ç½®
        - ğŸ”§ terratorchä¾å­˜é–¢ä¿‚ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
        - ğŸ”§ Prithvi-EO-2.0ãƒ¢ãƒ‡ãƒ«ï¼ˆ1.28GBï¼‰ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æº–å‚™
        - ğŸ”§ Standard Plan (2GB RAM) ç’°å¢ƒã®æœ€é©åŒ–
        """)
    
    # ãƒ¢ãƒ‡ãƒ«æƒ…å ±è¡¨ç¤ºã‚’ä¿®æ­£
    with st.sidebar:
        st.subheader("ğŸ¤– ãƒ¢ãƒ‡ãƒ«æƒ…å ±")
        if hasattr(st.session_state, 'model') and st.session_state.model is not None:
            if INFERENCE_AVAILABLE == True:
                st.success("âœ… **å®Ÿéš›ã®Prithvi-EO-2.0ãƒ¢ãƒ‡ãƒ«**ã‚’ä½¿ç”¨ä¸­ã§ã™ã€‚")
                st.info("ğŸ›°ï¸ terratorch + SemanticSegmentationTask")
                st.info("ğŸ“Š main.pyã¨åŒã˜æ–¹å¼")
            elif isinstance(st.session_state.model, AdvancedPrithviModel):
                st.warning("âš ï¸ **ç‹¬è‡ªPrithviãƒ¢ãƒ‡ãƒ«**ã‚’ä½¿ç”¨ä¸­ã§ã™ã€‚")
                st.info("ğŸš€ Standard Plan: 2GB RAMç’°å¢ƒã§Prithvié¢¨ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’å‹•ä½œ")
            elif isinstance(st.session_state.model, SimpleCNNModel):
                st.error("âš ï¸ **ç°¡æ˜“ãƒ¢ãƒ‡ãƒ«**ã‚’ä½¿ç”¨ä¸­ã§ã™ã€‚")
                st.error("âš ï¸ **æ³¨æ„**: ç¾åœ¨ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ä¸­ã§ã™ã€‚å®Ÿéš›ã®Prithviãƒ¢ãƒ‡ãƒ«ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
                st.info("ğŸ’¡ å®Ÿéš›ã®Prithviãƒ¢ãƒ‡ãƒ«ãŒæ­£ã—ãèª­ã¿è¾¼ã¾ã‚Œã¦ã„ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
            else:
                st.info("ğŸ¤– ãƒ¢ãƒ‡ãƒ«ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã™ã€‚")
        else:
            st.error("âŒ ãƒ¢ãƒ‡ãƒ«ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    
    # ç”»åƒå‡¦ç†ã¨äºˆæ¸¬
    if uploaded_file is not None:
        try:
            # main.pyã¨åŒã˜ã‚ˆã†ã«ç”»åƒã‚’èª­ã¿è¾¼ã¿
            if uploaded_file.name.lower().endswith(('.tif', '.tiff')):
                # TIFFãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆã¯rasterioã§èª­ã¿è¾¼ã¿ï¼ˆå¤šãƒãƒ³ãƒ‰å¯¾å¿œï¼‰
                import tempfile
                import rasterio
                
                with tempfile.NamedTemporaryFile(delete=False, suffix='.tif') as tmp_file:
                    tmp_file.write(uploaded_file.getvalue())
                    tmp_path = tmp_file.name
                
                try:
                    with rasterio.open(tmp_path) as src:
                        # å…¨ãƒãƒ³ãƒ‰ã‚’èª­ã¿è¾¼ã¿
                        img_data = src.read()  # Shape: (bands, height, width)
                        profile = src.profile.copy()
                        
                        st.info(f"TIFFãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿: ãƒãƒ³ãƒ‰æ•°={img_data.shape[0]}, ã‚µã‚¤ã‚º={img_data.shape[1]}x{img_data.shape[2]}")
                        
                        # (bands, height, width) â†’ (height, width, bands) ã«å¤‰æ›
                        rgb_image = img_data.transpose(1, 2, 0)
                        
                        # ãƒ‡ãƒ¼ã‚¿å‹ç¢ºèª
                        st.info(f"ãƒ‡ãƒ¼ã‚¿å‹: {rgb_image.dtype}, å€¤åŸŸ: {rgb_image.min()}-{rgb_image.max()}")
                        
                finally:
                    os.unlink(tmp_path)
                    
            else:
                # PNG/JPEGãªã©ã®é€šå¸¸ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«
                image = Image.open(uploaded_file)
                rgb_image = np.array(image)
                
                st.info(f"é€šå¸¸ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿: å½¢çŠ¶={rgb_image.shape}, ãƒ‡ãƒ¼ã‚¿å‹={rgb_image.dtype}")
            
            st.success("âœ… ç”»åƒå‡¦ç†å®Œäº†!")
            
            # ç”»åƒæƒ…å ±è¡¨ç¤º
            st.subheader("ğŸ“· ç”»åƒæƒ…å ±")
            col1, col2 = st.columns(2)
            
            with col1:
                st.write("**åŸºæœ¬æƒ…å ±**:")
                st.write(f"- ã‚µã‚¤ã‚º: {rgb_image.shape[1]}x{rgb_image.shape[0]}")
                st.write(f"- ãƒãƒ£ãƒ³ãƒãƒ«æ•°: {rgb_image.shape[2] if len(rgb_image.shape) > 2 else 1}")
                st.write(f"- ãƒ‡ãƒ¼ã‚¿å‹: {rgb_image.dtype}")
                st.write(f"- å€¤åŸŸ: {rgb_image.min()} - {rgb_image.max()}")
                
            with col2:
                st.write("**å‡¦ç†æƒ…å ±**:")
                # ç”»åƒå‰å‡¦ç†ï¼ˆãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å‡¦ç†ï¼‰
                try:
                    # main.pyã¨åŒã˜å‰å‡¦ç†
                    processed_image = preprocess_image_like_main(rgb_image)
                    if processed_image is not None:
                        # inference.pyã¨åŒã˜RGBè¡¨ç¤ºä½œæˆ
                        sentinel2_rgb = create_rgb_like_inference(processed_image)
                        if sentinel2_rgb is not None:
                            st.success("âœ… inference.pyæ–¹å¼RGBè¡¨ç¤ºä½œæˆå®Œäº†")
                            display_rgb_image = sentinel2_rgb
                            st.info("ğŸ›°ï¸ inference.pyæ–¹å¼Sentinel-2è¡¨ç¤ºã‚’ä½¿ç”¨")
                        else:
                            display_rgb_image = rgb_image
                            st.info("ğŸ“· å…ƒç”»åƒã‚’ä½¿ç”¨")
                        
                        # ãƒ¢ãƒ‡ãƒ«ç”¨ãƒ†ãƒ³ã‚½ãƒ«ä½œæˆ
                        processed_tensor = create_tensor_for_model(processed_image)
                        st.success(f"âœ… ãƒ¢ãƒ‡ãƒ«ç”¨ãƒ†ãƒ³ã‚½ãƒ«ä½œæˆå®Œäº†: {processed_tensor.shape}")
                    else:
                        st.error("âŒ å‰å‡¦ç†ã«å¤±æ•—")
                        processed_tensor = None
                        display_rgb_image = rgb_image
                        
                except Exception as preprocess_error:
                    st.error(f"âŒ å‰å‡¦ç†ã‚¨ãƒ©ãƒ¼: {preprocess_error}")
                    processed_tensor = None
                    display_rgb_image = rgb_image
                    st.warning("âš ï¸ å‰å‡¦ç†ã«å¤±æ•—ã€å…ƒç”»åƒã‚’ä½¿ç”¨")
            
            # å…¥åŠ›ç”»åƒãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
            st.subheader("ğŸ–¼ï¸ å…¥åŠ›ç”»åƒãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
            st.image(display_rgb_image, caption="å‡¦ç†æ¸ˆã¿Sentinel-2 RGBç”»åƒ", use_column_width=True)
            
            # äºˆæ¸¬å®Ÿè¡Œ
            st.header("ğŸ§  AIæ´ªæ°´æ¤œå‡º")
            
            # ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—ã®ç¢ºèªè¡¨ç¤º
            if INFERENCE_AVAILABLE == True:
                st.success("âœ… **å®Ÿéš›ã®Prithvi-EO-2.0ãƒ¢ãƒ‡ãƒ«**ã‚’ä½¿ç”¨ä¸­ã§ã™ï¼ˆmain.pyã¨åŒã˜ï¼‰ã€‚")
                st.info("ğŸ›°ï¸ terratorch + SemanticSegmentationTaskä½¿ç”¨")
            elif isinstance(st.session_state.model, SimpleCNNModel):
                st.error("âš ï¸ **æ³¨æ„**: ç¾åœ¨ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ä¸­ã§ã™ã€‚å®Ÿéš›ã®Prithviãƒ¢ãƒ‡ãƒ«ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
                st.info("ğŸ’¡ å®Ÿéš›ã®Prithviãƒ¢ãƒ‡ãƒ«ãŒæ­£ã—ãèª­ã¿è¾¼ã¾ã‚Œã¦ã„ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
            elif isinstance(st.session_state.model, AdvancedPrithviModel):
                st.warning("âš ï¸ **ç‹¬è‡ªPrithviãƒ¢ãƒ‡ãƒ«**ã‚’ä½¿ç”¨ä¸­ã§ã™ã€‚")
            else:
                st.warning("âš ï¸ **æœªçŸ¥ã®ãƒ¢ãƒ‡ãƒ«**ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã™ã€‚")
            
            predict_button = st.button("ğŸ” æ´ªæ°´æ¤œå‡ºã‚’å®Ÿè¡Œ", type="primary", use_container_width=True)
            
            if predict_button and processed_tensor is not None:
                try:
                    # display_rgb_imageãŒå­˜åœ¨ã—ãªã„å ´åˆã¯å…ƒç”»åƒã‚’ä½¿ç”¨
                    if 'display_rgb_image' not in locals():
                        display_rgb_image = rgb_image
                        st.info("ğŸ“· å…ƒç”»åƒã‚’ä½¿ç”¨ã—ã¦æ¨è«–ã‚’å®Ÿè¡Œ")
                    
                    with st.spinner("ğŸ”® æ´ªæ°´æ¤œå‡ºã‚’å®Ÿè¡Œä¸­..."):
                        # terratorchä½¿ç”¨æ™‚ã¯main.pyã¨åŒã˜æ–¹å¼
                        if INFERENCE_AVAILABLE == True:
                            st.info("ğŸ”„ main.pyã¨åŒã˜æ–¹å¼ã§æ¨è«–å®Ÿè¡Œä¸­...")
                            # main.pyã¨åŒã˜run_modelé–¢æ•°ã‚’ä½¿ç”¨
                            prediction = run_model(
                                processed_tensor, 
                                st.session_state.model, 
                                st.session_state.data_module
                            )
                            
                            # äºˆæ¸¬çµæœã‹ã‚‰ãƒã‚¹ã‚¯ã‚’ä½œæˆ
                            flood_prob = torch.softmax(prediction, dim=1)[0, 1].cpu().numpy()
                            flood_mask = flood_prob > 0.5  # 50%ä»¥ä¸Šã§æ´ªæ°´åˆ¤å®š
                            
                            st.success("âœ… main.pyæ–¹å¼ã§ã®æ¨è«–å®Œäº†")
                        else:
                            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ™‚ã¯ç‹¬è‡ªå®Ÿè£…
                            flood_mask, flood_prob = create_realistic_flood_prediction(
                                display_rgb_image, processed_tensor, st.session_state.model
                            )
                        
                        # äºˆæ¸¬ãƒã‚¹ã‚¯ç”»åƒã‚’ä½œæˆï¼ˆç™½é»’ï¼‰
                        prediction_image = np.zeros_like(display_rgb_image)
                        prediction_image[flood_mask] = [255, 255, 255]  # æ´ªæ°´=ç™½
                        # éæ´ªæ°´ã‚¨ãƒªã‚¢ã¯é»’ã®ã¾ã¾ï¼ˆ0, 0, 0ï¼‰
                        
                        # ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤ç”»åƒã‚’ä½œæˆ
                        overlay_image = create_prediction_overlay(display_rgb_image, flood_mask)
                        
                        # çµ±è¨ˆè¨ˆç®—
                        total_pixels = flood_mask.size
                        flood_pixels = np.sum(flood_mask)
                        flood_percentage = (flood_pixels / total_pixels) * 100
                        
                        st.success("âœ… æ´ªæ°´æ¤œå‡ºå®Œäº†!")
                        
                        # å‚è€ƒç”»åƒã¨åŒã˜3ã‚«ãƒ©ãƒ è¡¨ç¤º
                        st.subheader("ğŸ“Š çµæœ")
                        
                        col1, col2, col3 = st.columns(3)
                        
                        with col1:
                            st.markdown("**Input Image**")
                            st.image(display_rgb_image, use_column_width=True)
                            
                        with col2:
                            st.markdown("**Prediction**")
                            st.image(prediction_image, use_column_width=True)
                            
                        with col3:
                            st.markdown("**Overlay**")
                            st.image(overlay_image, use_column_width=True)
                        
                        # çµ±è¨ˆæƒ…å ±ã‚’ç°¡æ½”ã«è¡¨ç¤º
                        st.subheader("ğŸ“ˆ æ¤œå‡ºçµæœ")
                        
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.metric("æ´ªæ°´æ¤œå‡ºç‡", f"{flood_percentage:.2f}%")
                        with col2:
                            st.metric("æ´ªæ°´ãƒ”ã‚¯ã‚»ãƒ«æ•°", f"{flood_pixels:,}")
                        with col3:
                            st.metric("ç·ãƒ”ã‚¯ã‚»ãƒ«æ•°", f"{total_pixels:,}")
                        
                        # ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«åˆ¤å®š
                        if flood_percentage > 20:
                            st.error("ğŸš¨ **é«˜ãƒªã‚¹ã‚¯**: å¤§è¦æ¨¡ãªæ´ªæ°´ã®å¯èƒ½æ€§")
                        elif flood_percentage > 5:
                            st.warning("âš ï¸ **ä¸­ãƒªã‚¹ã‚¯**: éƒ¨åˆ†çš„ãªæ´ªæ°´ã®å¯èƒ½æ€§")
                        else:
                            st.info("âœ… **ä½ãƒªã‚¹ã‚¯**: é™å®šçš„ãªæ°´åŸŸæ¤œå‡º")
                        
                        # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚»ã‚¯ã‚·ãƒ§ãƒ³
                        st.subheader("ğŸ’¾ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")
                        
                        col1, col2, col3 = st.columns(3)
                        
                        with col1:
                            # å…¥åŠ›ç”»åƒãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆSentinel-2 RGBï¼‰
                            img_buffer = io.BytesIO()
                            Image.fromarray(display_rgb_image).save(img_buffer, format='PNG')
                            st.download_button(
                                label="å…¥åŠ›ç”»åƒã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                                data=img_buffer.getvalue(),
                                file_name="input_image.png",
                                mime="image/png"
                            )
                        
                        with col2:
                            # äºˆæ¸¬ç”»åƒãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
                            pred_buffer = io.BytesIO()
                            Image.fromarray(prediction_image).save(pred_buffer, format='PNG')
                            st.download_button(
                                label="äºˆæ¸¬çµæœã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                                data=pred_buffer.getvalue(),
                                file_name="prediction.png",
                                mime="image/png"
                            )
                        
                        with col3:
                            # ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤ç”»åƒãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
                            overlay_buffer = io.BytesIO()
                            Image.fromarray(overlay_image).save(overlay_buffer, format='PNG')
                            st.download_button(
                                label="ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                                data=overlay_buffer.getvalue(),
                                file_name="overlay.png",
                                mime="image/png"
                            )
                            
                except Exception as e:
                    st.error(f"âŒ **æ¨è«–ã‚¨ãƒ©ãƒ¼**: {e}")
                    st.info("ğŸ’¡ ç”»åƒå½¢å¼ã‚„å‰å‡¦ç†ã«å•é¡ŒãŒã‚ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
                    import traceback
                    st.code(traceback.format_exc())
            
        except Exception as e:
            st.error(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
            st.markdown("### ğŸ”§ ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°")
            st.markdown("""
            - ãƒ•ã‚¡ã‚¤ãƒ«ãŒæ­£ã—ã„TIFFå½¢å¼ã‹ç¢ºèªã—ã¦ãã ã•ã„
            - ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãŒ100MBä»¥ä¸‹ã‹ç¢ºèªã—ã¦ãã ã•ã„
            - å¤šãƒãƒ³ãƒ‰ç”»åƒï¼ˆæœ€ä½1ãƒãƒ³ãƒ‰ä»¥ä¸Šï¼‰ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„
            """)
    
    # ãƒ•ãƒƒã‚¿ãƒ¼
    st.markdown("---")
    st.markdown("""
    <div style='text-align: center; color: #666;'>
        <p>ğŸŒŠ Prithvi-EO-2.0 æ´ªæ°´æ¤œå‡ºã‚·ã‚¹ãƒ†ãƒ  | Powered by IBM & NASA | Running on Render</p>
        <p>ãƒ¢ãƒ‡ãƒ«: <a href='https://huggingface.co/ibm-nasa-geospatial/Prithvi-EO-2.0-300M-TL-Sen1Floods11'>Hugging Face</a> | 
        ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰: <a href='https://github.com/shirokawakita/demo_prithvi_eo_2_300m_sen1floods'>GitHub</a></p>
    </div>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()