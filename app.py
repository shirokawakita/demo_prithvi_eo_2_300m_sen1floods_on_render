import streamlit as st
import torch
import torch.nn as nn
import numpy as np
from PIL import Image
import io
import base64
import os
import yaml
import rasterio
from huggingface_hub import hf_hub_download
from pathlib import Path
from skimage.transform import resize
import cv2
import gc
import asyncio
import threading

# Streamlitè¨­å®š
st.set_page_config(
    page_title="Prithvi-EO-2.0 æ´ªæ°´æ¤œå‡º",
    page_icon="ğŸŒŠ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—å•é¡Œã‚’ä¿®æ­£
def fix_event_loop():
    """ã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—ã®å•é¡Œã‚’ä¿®æ­£"""
    try:
        loop = asyncio.get_event_loop()
        if loop.is_running():
            # æ–°ã—ã„ã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—ã‚’ä½œæˆ
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
    except RuntimeError:
        # ã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯æ–°ã—ãä½œæˆ
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)

# åˆæœŸåŒ–æ™‚ã«ã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—ã‚’ä¿®æ­£
fix_event_loop()

# ç’°å¢ƒå¤‰æ•°è¨­å®š
def configure_streamlit():
    """Streamlitã®è¨­å®šã‚’ç’°å¢ƒå¤‰æ•°ã§è¡Œã†"""
    os.environ['STREAMLIT_SERVER_HEADLESS'] = 'true'
    os.environ['STREAMLIT_SERVER_PORT'] = str(os.environ.get('PORT', 8501))
    os.environ['STREAMLIT_SERVER_ADDRESS'] = '0.0.0.0'
    os.environ['STREAMLIT_SERVER_ENABLE_CORS'] = 'false'
    os.environ['STREAMLIT_SERVER_ENABLE_XSRF_PROTECTION'] = 'false'
    os.environ['STREAMLIT_SERVER_MAX_UPLOAD_SIZE'] = '100'
    os.environ['STREAMLIT_BROWSER_GATHER_USAGE_STATS'] = 'false'

configure_streamlit()

class SimpleCNNModel(nn.Module):
    """ç°¡å˜ãªCNNãƒ¢ãƒ‡ãƒ«ï¼ˆãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ç”¨ï¼‰"""
    def __init__(self, in_channels=6, num_classes=2):
        super(SimpleCNNModel, self).__init__()
        self.conv1 = nn.Conv2d(in_channels, 64, kernel_size=3, padding=1)
        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)
        self.conv3 = nn.Conv2d(128, num_classes, kernel_size=1)
        self.relu = nn.ReLU()
        self.upsample = nn.Upsample(size=(512, 512), mode='bilinear', align_corners=False)
    
    def forward(self, x):
        x = self.relu(self.conv1(x))
        x = self.relu(self.conv2(x))
        x = self.conv3(x)
        x = self.upsample(x)
        return x

class PrithviModelLoader:
    def __init__(self):
        self.repo_id = "ibm-nasa-geospatial/Prithvi-EO-2.0-300M-TL-Sen1Floods11"
        self.model_filename = "Prithvi-EO-V2-300M-TL-Sen1Floods11.pt"
        self.config_filename = "config.yaml"
        self.cache_dir = Path("/tmp/prithvi_cache")
        self.cache_dir.mkdir(exist_ok=True)
    
    @st.cache_resource
    def download_and_load_model(_self):
        """ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦èª­ã¿è¾¼ã¿"""
        try:
            with st.spinner("Prithviãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­... (ç´„1.28GB)"):
                progress_bar = st.progress(0)
                status_text = st.empty()
                
                status_text.text("ğŸ”„ ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­...")
                progress_bar.progress(25)
                
                # ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
                try:
                    model_path = hf_hub_download(
                        repo_id=_self.repo_id,
                        filename=_self.model_filename,
                        cache_dir=str(_self.cache_dir)
                    )
                    progress_bar.progress(50)
                except Exception as download_error:
                    st.warning(f"âš ï¸ ãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {download_error}")
                    st.info("ğŸ’¡ ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¾ã™")
                    return _self._create_placeholder_model(), {}
                
                status_text.text("ğŸ”„ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­...")
                progress_bar.progress(75)
                
                # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
                try:
                    config_path = hf_hub_download(
                        repo_id=_self.repo_id,
                        filename=_self.config_filename,
                        cache_dir=str(_self.cache_dir)
                    )
                    
                    with open(config_path, 'r') as f:
                        config = yaml.safe_load(f)
                except Exception as config_error:
                    st.warning(f"âš ï¸ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚¨ãƒ©ãƒ¼: {config_error}")
                    config = {}
                
                progress_bar.progress(90)
                status_text.text("ğŸ”„ ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ä¸­...")
                
                # ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
                try:
                    device = torch.device('cpu')
                    
                    # Torchãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿
                    model_data = torch.load(model_path, map_location=device)
                    
                    st.write(f"ğŸ“‹ ãƒ¢ãƒ‡ãƒ«ãƒ‡ãƒ¼ã‚¿å‹: {type(model_data)}")
                    
                    if isinstance(model_data, dict):
                        st.write(f"ğŸ“‹ åˆ©ç”¨å¯èƒ½ãªã‚­ãƒ¼: {list(model_data.keys())}")
                        
                        # ä¸€èˆ¬çš„ãªã‚­ãƒ¼ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è©¦è¡Œ
                        model = None
                        for key in ['model', 'state_dict', 'model_state_dict', 'net', 'network']:
                            if key in model_data:
                                st.write(f"ğŸ”‘ ã‚­ãƒ¼ '{key}' ã‚’ä½¿ç”¨")
                                try:
                                    if key == 'state_dict' or key == 'model_state_dict':
                                        # state_dictã®å ´åˆã¯æ–°ã—ã„ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆ
                                        model = SimpleCNNModel()
                                        # éƒ¨åˆ†çš„ã«state_dictã‚’èª­ã¿è¾¼ã¿ï¼ˆã‚µã‚¤ã‚ºãŒåˆã‚ãªã„éƒ¨åˆ†ã¯ç„¡è¦–ï¼‰
                                        model.load_state_dict(model_data[key], strict=False)
                                    else:
                                        model = model_data[key]
                                    break
                                except Exception as load_error:
                                    st.warning(f"âš ï¸ ã‚­ãƒ¼ '{key}' ã§ã®ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—: {load_error}")
                                    continue
                        
                        # ã©ã®ã‚­ãƒ¼ã§ã‚‚èª­ã¿è¾¼ã‚ãªã„å ´åˆ
                        if model is None:
                            st.warning("âš ï¸ æ¨™æº–çš„ãªã‚­ãƒ¼ã§ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸ")
                            model = _self._create_placeholder_model()
                    
                    else:
                        # ç›´æ¥ãƒ¢ãƒ‡ãƒ«ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®å ´åˆ
                        model = model_data
                    
                    # ãƒ¢ãƒ‡ãƒ«ã‚’è©•ä¾¡ãƒ¢ãƒ¼ãƒ‰ã«è¨­å®š
                    if hasattr(model, 'eval'):
                        model.eval()
                    
                    progress_bar.progress(100)
                    status_text.text("âœ… å®Œäº†!")
                    
                    # ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
                    gc.collect()
                    
                    return model, config
                    
                except Exception as model_error:
                    st.error(f"âŒ ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {model_error}")
                    st.info("ğŸ’¡ ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¾ã™")
                    return _self._create_placeholder_model(), {}
                    
        except Exception as e:
            st.error(f"âŒ å…¨ä½“çš„ãªã‚¨ãƒ©ãƒ¼: {e}")
            return _self._create_placeholder_model(), {}
    
    def _create_placeholder_model(self):
        """ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆ"""
        st.info("ğŸ”§ ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆä¸­...")
        model = SimpleCNNModel(in_channels=6, num_classes=2)
        model.eval()
        return model

class ImageProcessor:
    def __init__(self):
        self.target_size = (512, 512)
    
    def process_sentinel2_image(self, uploaded_file):
        """Sentinel-2ç”»åƒã‚’å‡¦ç†"""
        try:
            # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸€æ™‚ä¿å­˜
            temp_path = f"/tmp/{uploaded_file.name}"
            with open(temp_path, "wb") as f:
                f.write(uploaded_file.getbuffer())
            
            # Rasterioã§ç”»åƒèª­ã¿è¾¼ã¿
            with rasterio.open(temp_path) as src:
                # å…¨ãƒãƒ³ãƒ‰ã‚’èª­ã¿è¾¼ã¿
                image_data = src.read()
                
                # ãƒãƒ³ãƒ‰æ•°ç¢ºèª
                st.write(f"ğŸ“Š å…ƒç”»åƒ: {image_data.shape} (ãƒãƒ³ãƒ‰, é«˜ã•, å¹…)")
                
                if image_data.shape[0] < 6:
                    # ãƒãƒ³ãƒ‰ãŒè¶³ã‚Šãªã„å ´åˆã¯ç¹°ã‚Šè¿”ã—ã§è£œå®Œ
                    st.warning(f"âš ï¸ ãƒãƒ³ãƒ‰æ•°ä¸è¶³ ({image_data.shape[0]} < 6). è£œå®Œã—ã¾ã™.")
                    while image_data.shape[0] < 6:
                        image_data = np.concatenate([image_data, image_data[:1]], axis=0)
                
                # å¿…è¦ãª6ãƒãƒ³ãƒ‰ã‚’é¸æŠ
                selected_bands = image_data[:6]
                
                # ãƒ‡ãƒ¼ã‚¿å‹ç¢ºèªãƒ»å¤‰æ›
                st.write(f"ğŸ“Š ãƒ‡ãƒ¼ã‚¿å‹: {selected_bands.dtype}")
                if selected_bands.dtype == np.uint16:
                    selected_bands = selected_bands.astype(np.float32)
                elif selected_bands.dtype == np.int16:
                    selected_bands = selected_bands.astype(np.float32)
                
                # ã‚µã‚¤ã‚ºèª¿æ•´
                st.write(f"ğŸ“Š ãƒªã‚µã‚¤ã‚ºå‰: {selected_bands.shape}")
                processed_bands = []
                for i, band in enumerate(selected_bands):
                    resized_band = resize(band, self.target_size, preserve_range=True, anti_aliasing=True)
                    processed_bands.append(resized_band)
                
                processed_image = np.stack(processed_bands, axis=0)
                st.write(f"ğŸ“Š ãƒªã‚µã‚¤ã‚ºå¾Œ: {processed_image.shape}")
                
                # æ­£è¦åŒ–
                processed_image = self.normalize_image(processed_image)
                
                # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
                os.remove(temp_path)
                
                return processed_image
                
        except Exception as e:
            # ã‚¨ãƒ©ãƒ¼æ™‚ã‚‚ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
            if 'temp_path' in locals() and os.path.exists(temp_path):
                os.remove(temp_path)
            raise Exception(f"ç”»åƒå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
    
    def normalize_image(self, image):
        """ç”»åƒã‚’æ­£è¦åŒ–"""
        # åŸºæœ¬çš„ãªæ­£è¦åŒ– (0-1ç¯„å›²)
        image_min = np.min(image)
        image_max = np.max(image)
        
        if image_max > image_min:
            image = (image - image_min) / (image_max - image_min)
        else:
            image = np.zeros_like(image)
        
        return image.astype(np.float32)
    
    def create_rgb_image(self, image_data):
        """RGBç”»åƒã‚’ä½œæˆï¼ˆå¯è¦–åŒ–ç”¨ï¼‰"""
        try:
            # ãƒãƒ³ãƒ‰3(Red), 2(Green), 1(Blue)ã‚’ä½¿ç”¨
            rgb = np.stack([
                image_data[2] if image_data.shape[0] > 2 else image_data[0],  # Red
                image_data[1] if image_data.shape[0] > 1 else image_data[0],  # Green  
                image_data[0]   # Blue
            ], axis=-1)
            
            # 0-255ã«æ­£è¦åŒ–
            rgb = (rgb * 255).astype(np.uint8)
            
            return rgb
        except Exception as e:
            st.error(f"RGBç”»åƒä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
            # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«ç”»åƒã‚’è¿”ã™
            gray = (image_data[0] * 255).astype(np.uint8)
            return np.stack([gray, gray, gray], axis=-1)
    
    def create_prediction_overlay(self, rgb_image, prediction_mask):
        """äºˆæ¸¬ãƒã‚¹ã‚¯ã‚’RGBç”»åƒã«ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤"""
        try:
            overlay = rgb_image.copy()
            
            # æ´ªæ°´é ˜åŸŸã‚’èµ¤è‰²ã§ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤
            flood_mask = prediction_mask == 1
            overlay[flood_mask] = [255, 0, 0]  # èµ¤è‰²
            
            # é€æ˜åº¦ã‚’é©ç”¨
            alpha = 0.6
            result = cv2.addWeighted(rgb_image, 1-alpha, overlay, alpha, 0)
            
            return result
        except Exception as e:
            st.error(f"ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤ä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
            return rgb_image

def create_download_link(image, filename):
    """ç”»åƒã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒªãƒ³ã‚¯ã‚’ä½œæˆ"""
    try:
        pil_image = Image.fromarray(image)
        buffer = io.BytesIO()
        pil_image.save(buffer, format='PNG')
        buffer.seek(0)
        
        b64 = base64.b64encode(buffer.read()).decode()
        href = f'<a href="data:image/png;base64,{b64}" download="{filename}" style="text-decoration: none; color: #1f77b4;">ğŸ“¥ {filename}</a>'
        return href
    except Exception as e:
        return f"ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}"

def show_system_info():
    """ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±ã‚’è¡¨ç¤º"""
    if st.sidebar.checkbox("ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±", value=False):
        try:
            import psutil
            memory = psutil.virtual_memory()
            st.sidebar.write(f"ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: {memory.percent:.1f}%")
            st.sidebar.write(f"åˆ©ç”¨å¯èƒ½ãƒ¡ãƒ¢ãƒª: {memory.available / 1024**3:.2f}GB")
        except:
            st.sidebar.write("ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±ã‚’å–å¾—ã§ãã¾ã›ã‚“")

def main():
    st.title("ğŸŒŠ Prithvi-EO-2.0 æ´ªæ°´æ¤œå‡ºã‚·ã‚¹ãƒ†ãƒ ")
    st.markdown("""
    **IBM & NASAãŒé–‹ç™ºã—ãŸPrithvi-EO-2.0ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ãŸSentinel-2ç”»åƒã‹ã‚‰ã®æ´ªæ°´æ¤œå‡º**
    
    ã“ã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¯[Render](https://render.com)ä¸Šã§å‹•ä½œã—ã¦ã„ã¾ã™ã€‚
    """)
    
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼
    st.sidebar.header("ğŸ”§ è¨­å®š")
    st.sidebar.markdown("### ãƒ¢ãƒ‡ãƒ«æƒ…å ±")
    st.sidebar.info("""
    - **ãƒ¢ãƒ‡ãƒ«**: Prithvi-EO-2.0-300M
    - **ã‚µã‚¤ã‚º**: 1.28GB
    - **ã‚¿ã‚¹ã‚¯**: æ´ªæ°´ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³
    - **å…¥åŠ›**: Sentinel-2 (6ãƒãƒ³ãƒ‰)
    - **è§£åƒåº¦**: 512Ã—512ãƒ”ã‚¯ã‚»ãƒ«
    """)
    
    # ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±è¡¨ç¤º
    show_system_info()
    
    # ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–
    if 'model_loaded' not in st.session_state:
        st.session_state.model_loaded = False
    
    if not st.session_state.model_loaded:
        st.info("ğŸš€ ãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ–ã—ã¦ã„ã¾ã™...")
        
        try:
            model_loader = PrithviModelLoader()
            model, config = model_loader.download_and_load_model()
            
            if model is not None:
                st.session_state.model = model
                st.session_state.config = config
                st.session_state.model_loaded = True
                
                # ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ãƒ¢ãƒ‡ãƒ«ã‹ã©ã†ã‹ã‚’ç¢ºèª
                if isinstance(model, SimpleCNNModel):
                    st.warning("âš ï¸ ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ãƒ¢ãƒ¼ãƒ‰ã§å‹•ä½œã—ã¦ã„ã¾ã™ã€‚ãƒ‡ãƒ¢ç”¨ã®äºˆæ¸¬ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚")
                else:
                    st.success("âœ… Prithviãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿å®Œäº†!")
                    st.balloons()
            else:
                st.error("âŒ ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ")
                st.stop()
                
        except Exception as e:
            st.error(f"âŒ ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            st.stop()
    
    # ç”»åƒå‡¦ç†å™¨åˆæœŸåŒ–
    processor = ImageProcessor()
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
    st.header("ğŸ“ Sentinel-2ç”»åƒã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
    
    uploaded_file = st.file_uploader(
        "TIFFãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„",
        type=['tif', 'tiff'],
        help="Sentinel-2 L1Cã¾ãŸã¯å¤šãƒãƒ³ãƒ‰GeoTIFFãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆæœ€å¤§100MBï¼‰"
    )
    
    # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿æƒ…å ±
    st.markdown("### ğŸŒ ãƒ†ã‚¹ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿")
    st.info("""
    ä»¥ä¸‹ã®åœ°åŸŸã®Sentinel-2æ´ªæ°´ç”»åƒã‚’ãƒ†ã‚¹ãƒˆã§ãã¾ã™ï¼š
    - ğŸ‡®ğŸ‡³ **ã‚¤ãƒ³ãƒ‰**: ãƒ¢ãƒ³ã‚¹ãƒ¼ãƒ³ã«ã‚ˆã‚‹æ´ªæ°´
    - ğŸ‡ªğŸ‡¸ **ã‚¹ãƒšã‚¤ãƒ³**: æ²³å·æ°¾æ¿«
    - ğŸ‡ºğŸ‡¸ **ã‚¢ãƒ¡ãƒªã‚«**: ãƒãƒªã‚±ãƒ¼ãƒ³ã«ã‚ˆã‚‹æ´ªæ°´
    
    å…ƒã®ãƒªãƒã‚¸ãƒˆãƒªã‹ã‚‰ã‚µãƒ³ãƒ—ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ãŠè©¦ã—ãã ã•ã„ã€‚
    """)
    
    # ç”»åƒå‡¦ç†ã¨äºˆæ¸¬
    if uploaded_file is not None:
        try:
            # ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±è¡¨ç¤º
            st.success(f"âœ… ãƒ•ã‚¡ã‚¤ãƒ«å—ä¿¡: {uploaded_file.name} ({uploaded_file.size / 1024 / 1024:.1f} MB)")
            
            # ç”»åƒå‡¦ç†
            with st.spinner("ğŸ“Š ç”»åƒã‚’å‡¦ç†ä¸­..."):
                processed_image = processor.process_sentinel2_image(uploaded_file)
                
                # RGBå¯è¦–åŒ–ç”»åƒä½œæˆ
                rgb_image = processor.create_rgb_image(processed_image)
            
            st.success("âœ… ç”»åƒå‡¦ç†å®Œäº†!")
            
            # å…¥åŠ›ç”»åƒãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
            st.subheader("ğŸ–¼ï¸ å…¥åŠ›ç”»åƒãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
            col1, col2 = st.columns([2, 1])
            
            with col1:
                st.image(rgb_image, caption="RGBåˆæˆç”»åƒ (ãƒãƒ³ãƒ‰3,2,1)", use_column_width=True)
            
            with col2:
                st.markdown("**ç”»åƒæƒ…å ±**")
                st.write(f"- ã‚µã‚¤ã‚º: {processed_image.shape[1]}Ã—{processed_image.shape[2]}")
                st.write(f"- ãƒãƒ³ãƒ‰æ•°: {processed_image.shape[0]}")
                st.write(f"- ãƒ‡ãƒ¼ã‚¿å‹: {processed_image.dtype}")
                st.write(f"- å€¤åŸŸ: {processed_image.min():.3f} - {processed_image.max():.3f}")
            
            # äºˆæ¸¬å®Ÿè¡Œ
            st.header("ğŸ§  AIæ´ªæ°´æ¤œå‡º")
            
            if st.button("ğŸ” æ´ªæ°´æ¤œå‡ºã‚’å®Ÿè¡Œ", type="primary", use_container_width=True):
                try:
                    with st.spinner("ğŸ¤– Prithviãƒ¢ãƒ‡ãƒ«ã§äºˆæ¸¬ä¸­..."):
                        # é€²è¡ŒçŠ¶æ³è¡¨ç¤º
                        progress_bar = st.progress(0)
                        status_text = st.empty()
                        
                        status_text.text("ğŸ“Š ãƒ†ãƒ³ã‚½ãƒ«ã«å¤‰æ›ä¸­...")
                        progress_bar.progress(25)
                        
                        # ãƒ†ãƒ³ã‚½ãƒ«ã«å¤‰æ›
                        input_tensor = torch.from_numpy(processed_image).unsqueeze(0).float()
                        st.write(f"ğŸ“Š å…¥åŠ›ãƒ†ãƒ³ã‚½ãƒ«å½¢çŠ¶: {input_tensor.shape}")
                        
                        status_text.text("ğŸ§  AIäºˆæ¸¬å®Ÿè¡Œä¸­...")
                        progress_bar.progress(50)
                        
                        # äºˆæ¸¬å®Ÿè¡Œ
                        with torch.no_grad():
                            prediction = st.session_state.model(input_tensor)
                            st.write(f"ğŸ“Š äºˆæ¸¬å‡ºåŠ›å½¢çŠ¶: {prediction.shape}")
                            prediction_mask = torch.argmax(prediction, dim=1).squeeze().numpy()
                        
                        status_text.text("ğŸ¨ çµæœç”»åƒã‚’ç”Ÿæˆä¸­...")
                        progress_bar.progress(75)
                        
                        # ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤ç”»åƒä½œæˆ
                        overlay_image = processor.create_prediction_overlay(rgb_image, prediction_mask)
                        
                        progress_bar.progress(100)
                        status_text.text("âœ… å®Œäº†!")
                        
                        # ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
                        del prediction, input_tensor
                        gc.collect()
                    
                    # ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ãƒ¢ãƒ‡ãƒ«ä½¿ç”¨æ™‚ã®è­¦å‘Š
                    if isinstance(st.session_state.model, SimpleCNNModel):
                        st.warning("âš ï¸ ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹ãƒ‡ãƒ¢äºˆæ¸¬çµæœã§ã™ã€‚")
                    
                    # çµæœè¡¨ç¤º
                    st.header("ğŸ“Š æ¤œå‡ºçµæœ")
                    
                    # çµ±è¨ˆæƒ…å ±
                    total_pixels = prediction_mask.size
                    flood_pixels = np.sum(prediction_mask == 1)
                    flood_ratio = flood_pixels / total_pixels * 100
                    
                    col1, col2, col3 = st.columns(3)
                    col1.metric("ç·ãƒ”ã‚¯ã‚»ãƒ«æ•°", f"{total_pixels:,}")
                    col2.metric("æ´ªæ°´ãƒ”ã‚¯ã‚»ãƒ«æ•°", f"{flood_pixels:,}")
                    col3.metric("æ´ªæ°´é¢ç©ç‡", f"{flood_ratio:.2f}%")
                    
                    # çµæœç”»åƒè¡¨ç¤º
                    col1, col2, col3 = st.columns(3)
                    
                    with col1:
                        st.subheader("å…¥åŠ›ç”»åƒ (RGB)")
                        st.image(rgb_image, use_column_width=True)
                    
                    with col2:
                        st.subheader("æ´ªæ°´äºˆæ¸¬ãƒã‚¹ã‚¯")
                        mask_vis = (prediction_mask * 255).astype(np.uint8)
                        st.image(mask_vis, use_column_width=True)
                    
                    with col3:
                        st.subheader("ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤çµæœ")
                        st.image(overlay_image, use_column_width=True)
                    
                    # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚»ã‚¯ã‚·ãƒ§ãƒ³
                    st.subheader("ğŸ’¾ çµæœãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")
                    
                    col1, col2, col3 = st.columns(3)
                    
                    with col1:
                        st.markdown(create_download_link(rgb_image, "input_rgb.png"), unsafe_allow_html=True)
                    
                    with col2:
                        st.markdown(create_download_link(np.stack([mask_vis]*3, axis=-1), "prediction_mask.png"), unsafe_allow_html=True)
                    
                    with col3:
                        st.markdown(create_download_link(overlay_image, "flood_overlay.png"), unsafe_allow_html=True)
                    
                    # è§£é‡ˆã‚¬ã‚¤ãƒ‰
                    st.subheader("ğŸ“– çµæœã®è§£é‡ˆ")
                    st.markdown("""
                    - **ç™½ã„é ˜åŸŸ**: æ´ªæ°´ã¨äºˆæ¸¬ã•ã‚ŒãŸæ°´åŸŸ
                    - **é»’ã„é ˜åŸŸ**: éæ´ªæ°´åŸŸï¼ˆé™¸åœ°ï¼‰
                    - **èµ¤ã„é ˜åŸŸ**: ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤ç”»åƒã®æ´ªæ°´é ˜åŸŸ
                    
                    **æ³¨æ„**: ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ãƒ¢ãƒ¼ãƒ‰ã§ã¯å®Ÿéš›ã®æ´ªæ°´æ¤œå‡ºã§ã¯ãªãã€ãƒ‡ãƒ¢ç”¨ã®äºˆæ¸¬çµæœã‚’è¡¨ç¤ºã—ã¦ã„ã¾ã™ã€‚
                    """)
                    
                except Exception as predict_error:
                    st.error(f"âŒ äºˆæ¸¬ã‚¨ãƒ©ãƒ¼: {predict_error}")
                    st.write("ãƒ‡ãƒãƒƒã‚°æƒ…å ±:")
                    st.write(f"- ãƒ¢ãƒ‡ãƒ«å‹: {type(st.session_state.model)}")
                    st.write(f"- å…¥åŠ›ç”»åƒå½¢çŠ¶: {processed_image.shape}")
                    
        except Exception as e:
            st.error(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
            st.markdown("### ğŸ”§ ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°")
            st.markdown("""
            - ãƒ•ã‚¡ã‚¤ãƒ«ãŒæ­£ã—ã„TIFFå½¢å¼ã‹ç¢ºèªã—ã¦ãã ã•ã„
            - ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãŒ100MBä»¥ä¸‹ã‹ç¢ºèªã—ã¦ãã ã•ã„
            - å¤šãƒãƒ³ãƒ‰ç”»åƒï¼ˆæœ€ä½1ãƒãƒ³ãƒ‰ä»¥ä¸Šï¼‰ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„
            """)
    
    # ãƒ•ãƒƒã‚¿ãƒ¼
    st.markdown("---")
    st.markdown("""
    <div style='text-align: center; color: #666;'>
        <p>ğŸŒŠ Prithvi-EO-2.0 æ´ªæ°´æ¤œå‡ºã‚·ã‚¹ãƒ†ãƒ  | Powered by IBM & NASA | Running on Render</p>
        <p>ãƒ¢ãƒ‡ãƒ«: <a href='https://huggingface.co/ibm-nasa-geospatial/Prithvi-EO-2.0-300M-TL-Sen1Floods11'>Hugging Face</a> | 
        ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰: <a href='https://github.com/shirokawakita/demo_prithvi_eo_2_300m_sen1floods'>GitHub</a></p>
    </div>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()